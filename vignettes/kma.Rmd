---
title: "Computing Intron Retention With Keep Me Around (`kma`)"
author: "Harold Pimentel"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    toc: true
vignette: >
  %\VignetteIndexEntry{Walkthrough}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

This vignette described how to run the Keep Me Around `kma` suite to compute
intron retention in RNA-Seq experiments.

# General pipeline

The general pipeline is as follows:

1. **Pre-process** to generate intron coordinates and sequences
1. **Quantify** transcript expression using
   [eXpress](http://bio.math.berkeley.edu/eXpress/) against augmented
   transcriptome containing introns
1. **Post-process** to compute intron retention using `R` package

**TODO: Put a more detailed flowchart here**

# Installing

There are two required portions of the tool to perform intron retention
quantification. The **pre-process** step is written in python

## Installing the pre-processing tools

If you have installed the `R` package (see installing the post-processing
tools), then you have successfully installed the
pre-processing tools. From `R`, you can find the path by typing:

```{r}
system.file("preprocess", package="kma")
```

The only additional dependencies are the Python packages `pyfasta`, `biopython` and `pysam`.
Both packages can be installed via PyPI:

```{bash}
pip install pyfasta biopython pysam
```

## Installing the quantification tools

The tools needed for quantification are:

- [Bowtie 2](http://bowtie-bio.sourceforge.net/bowtie2/) short read aligner
- [eXpress](http://bio.math.berkeley.edu/eXpress/) RNA-Seq quantification tool

Please see the corresponding documentation on their respective web pages.

## Installing the post-processing tools

The post-processing tools are contained in an `R` packaged called `kma`.
Currently, the latest package is on
[Github](http://github.com/pachterlab/kma). To install, make sure you have
the `devtools` package installed and type

```{r, eval=FALSE}
devtools::install_github("http://github.com/pachterlab/kma")
```

# Generate intron coordinates (pre-processing)

The path can be found in R by typing `system.file("preprocess",
package="kma")`. Open a terminal and put this path in an environment variable:

```{bash}
PRE=/path/to/kma/preprocess
```

If you are on a Mac, the path might look like: /Library/Frameworks/R.framework/Versions/3.1/Resources/library/kma/preprocess

We are now ready to generate the introns. A typical call looks as follows:

```{bash}
python $PRE/generate_introns.py --genome seq.fa --gtf trans.gtf --extend N --out out_dir
```

With the inputs being:

- `--genome seq.fa`: **genome sequence**  in [Multi-FASTA
  format](http://en.wikipedia.org/wiki/FASTA_format) where contig names
  correspond to the GTF file.
- `--gtf trans.gtf`: **annotation file** in [GTF
  format](http://www.ensembl.org/info/website/upload/gff.html).
- `--extend N`: Optional. If set, `N` is the number of bases bases to overlap
  into the intron. Note, this should be at most `read_length - 1`.
- `--out out_dir`: A directory to write the outputs. Will be created if doesn't
  already exist.

The following outputs will then be put in `out_dir`:

- **introns.fa** - a FASTA file containing the intron sequences.
- **introns.bed** - BED file with coordinates used to quantify intron.
- **intron\_to\_transcripts.txt** - used later.

# Quantification

**Note**: Technically any quantification tool can be used with `kma_ir`, but currently
only support with `eXpress` is implemented. Please contact me if you're
interested in a quantification tool being supported.

Here, we will discuss quantification. After `generate_introns.py` is run,
`introns.fa` should be combined with the full transcript sequences. This can be
done using the Linux command `cat`:

```{bash}
cat trans.fa introns.fa > trans_and_introns.fa
```

If you called `--merge-in` and `--merge-out` with `generate_introns.py`, you
will already have the file `trans_and_introns.fa`. We will assume the file name
is `trans_and_introns` in the following sections, but the file name can be
anything.

After you've done this, this section requires the following steps:

1. Create the `Bowtie 2` index
1. Align reads to the augmented transcriptome
1. Quantify against the augmented transcriptome

## Creating the Bowtie 2 index

See the `Bowtie 2` manual for more advanced options.

```{bash}
bowtie2-build --offrate 1 trans_and_introns.fa trans_and_introns
```

This only has to be run once if you decide to change the gene annotation.

## Align reads

Once you have a `Bowtie 2` index, you can align any number of RNA-Seq
experiments to that index. The following arguments are recommended when running
Bowtie 2:

```{bash}
bowtie2 -k 200 --rdg 6,5 --rfg 6,5 --score-min L,-.6,-.4 -X trans_and_introns
    -1 left.fastq -2 right.fastq | samtools view -Sb - > hits.bam
```

## Quantify

Once you've aligned the reads, you can run eXpress against the alignments. See
the eXpress website for additional arguments. The general eXpress call is as
follows:

```{bash}
express trans_and_introns.fa hits.bam
```

# Computing intron retention (post-processing)

The first step is to the load the quantification data into `R`. The function
`read_express` takes a list of file names, sample names, and condition names.
`read_express` then returns a list with the attributes:

- `tpm` - a `data.frame` with TPM of all samples
- `uniq_counts` - a `data.frame` with the number of unique counts of all
  samples
- `all_data` - a list of `data.frame`s from all the eXpress output. Sorted by
  `target_id`.
- `sample` - a character vector for each sample, describing the sample (e.g.
  `tumor_rep1`)
- `condition` - a character vector for each sample describing the grouping
  (e.g. `tumor`)



# A worked example

## Organization
We recommend organizing your experiments in the following format:

```
experiment
|____conditionA
| |____rep1
| |____rep2
| |____rep3
|____conditionB
| |____rep1
| |____rep2
| |____rep3
```

where `experiment` is the top level for the particular set of experiments,
`conditionX` refers to the condition (e.g. tumor, or control), and `repY`
represents the biological replicates. This allows for a structured way to keep
track of your data as well as an easy way to load it in `R`.

## Pre-processing

Show the commands and do an ls to see what the output looks like

## Quantification

Simply provide the quantification results

## Post-processing

### Loading the files

**TODO: remove the eval=FALSE sections and actually include the data**
Since we organized our data nicely, we can load the data into R quite easily
using `Sys.glob`:

```{r eval=FALSE}
base_dir <- system.file("example", package="kma")
xprs_fnames <- Sys.glob(file.path(base_dir, "quantification/*/*/results.xprs"))
```

Sample names can be inferred from the organization as well:

```{r eval=FALSE}
sample_names <- sub(file.path(base_dir, "quantification/"), "", xprs_fnames) %>%
    sub("/results.xprs", "", .) %>%
    gsub("/", "", .)
```

Assuming you label your replicates according to the condition they are a part
of, you can also infer condition names:

```{r eval=FALSE}
condition_names <- sub("[0-9]+", "", sample_names)
```

You now have:

- `xprs_fnames` - a character vector of file names pointing to the
  quantification files
- `sample_names` - a character vector of identifiers for each sample
- `condition_names` - a character vector of identifiers of conditions

We can now load all the eXpress data into R:

```{r eval=FALSE}
xprs <- read_express(xprs_fnames, sample_names, condition_names)
```

This results in a named list with the following members:

```{r eval=FALSE}
names(xprs)
```

To create an `IntronRetention` object, you can call `newIntronRetention` with
the following command:

```{r eval=FALSE}
ir <- newIntronRetention(xprs$tpm, i2t, xprs$condition, xprs$uniq_counts)
```

### Filtering

#### Zero coverage

### Exploratory analysis

